{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jayanth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "Shape after flattening: (1, 67712)\n",
      "Flattened Output: [0.01292237 0.02385195 0.01220972 0.00762045 0.0059512 ]\n",
      "WARNING:tensorflow:From C:\\Users\\Jayanth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Raw Scores: [[0.21123864 0.192191   0.19746213 0.20174602 0.19736221]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Example data\n",
    "input_data = np.random.rand(1, 48,48,1)  # Replace with your actual input data shape\n",
    "\n",
    "# Create a model with convolutional layers and Flatten\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "# Add more convolutional layers as needed\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the flattened output\n",
    "image_path = 'D:\\\\Downloads\\\\Emotion Detection\\\\Emotion_Detection_CNN-main\\\\images\\\\cv6.png'\n",
    "image = np.expand_dims(cv2.imread(image_path, 0), axis=2)\n",
    "# image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (48, 48),interpolation = cv2.INTER_AREA)\n",
    "# plt.imshow(image)\n",
    "image = image.astype('float')/255.0\n",
    "image = img_to_array(image)\n",
    "# plt.imshow(image)\n",
    "image = np.expand_dims(image,axis=0)\n",
    "flattened_output = model.predict(image)\n",
    "\n",
    "# Print the shape of the flattened output\n",
    "print(\"Shape after flattening:\", flattened_output.shape)\n",
    "\n",
    "# Optionally, print the actual flattened values\n",
    "print(\"Flattened Output:\", flattened_output[0][40000:40005])\n",
    "# Example flattened vector\n",
    "flattened_vector = flattened_output  # Replace 100 with the size of your flattened vector\n",
    "\n",
    "# Create a simple model with a fully connected layer\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(units=64, activation='relu', input_shape=(None,1,67712)))  # Change 100 to the size of your flattened vector\n",
    "# Add more layers if needed\n",
    "model1.add(Dense(units=5, activation='softmax'))  # Output layer with 10 units (example)\n",
    "\n",
    "# Compile the model (you can customize the optimizer, loss, and metrics)\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Predict using the model\n",
    "raw_scores = model1.predict(flattened_vector)\n",
    "\n",
    "# Print the raw scores\n",
    "print(\"Raw Scores:\", raw_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027332FB6F20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 170ms/step\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m INTERESTED_CONV_LAYERS:\n\u001b[0;32m     19\u001b[0m     some_conv_layer \u001b[38;5;241m=\u001b[39m moodel\u001b[38;5;241m.\u001b[39mget_layer(layer[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_vector_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_conv_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m     pooled_grads \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mmean(grads, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     22\u001b[0m     iterate \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mfunction([moodel\u001b[38;5;241m.\u001b[39minput], [pooled_grads, some_conv_layer\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:4693\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   4681\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.backend.gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4682\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_generate_docs\n\u001b[0;32m   4683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradients\u001b[39m(loss, variables):\n\u001b[0;32m   4684\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the gradients of `loss` w.r.t. `variables`.\u001b[39;00m\n\u001b[0;32m   4685\u001b[0m \n\u001b[0;32m   4686\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4691\u001b[0m \u001b[38;5;124;03m        A gradients tensor.\u001b[39;00m\n\u001b[0;32m   4692\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   4695\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:177\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Creating the gradient graph for control flow mutates Operations.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# _mutation_lock ensures a Session.run call cannot occur between creating and\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# mutating new ops.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m--> 177\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m      \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolocate_gradients_with_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgate_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregation_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m      \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:518\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of gradients().\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 518\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.gradients is not supported when eager execution \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis enabled. Use tf.GradientTape instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m ys \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(_AsList(ys))\n\u001b[0;32m    521\u001b[0m xs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    522\u001b[0m     x\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;28;01mif\u001b[39;00m resource_variable_ops\u001b[38;5;241m.\u001b[39mis_resource_variable(x) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _AsList(xs)\n\u001b[0;32m    524\u001b[0m ]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "moodel = load_model('D:\\\\Downloads\\\\Emotion Detection\\\\Emotion_Detection_CNN-main\\\\model_dcnn.keras')\n",
    "sample_img = 'D:\\\\Downloads\\\\Emotion Detection\\\\Emotion_Detection_CNN-main\\\\images\\\\happy1.png'\n",
    "image = np.expand_dims(cv2.imread(sample_img, 0), axis=2)\n",
    "# image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (48, 48),interpolation = cv2.INTER_AREA)\n",
    "# plt.imshow(image)\n",
    "image = image.astype('float')/255.0\n",
    "image = img_to_array(image)\n",
    "# plt.imshow(image)\n",
    "image = np.expand_dims(image,axis=0)\n",
    "preds = moodel.predict(image)\n",
    "pred_vector_output = moodel.output[:, np.argmax(preds[0])]\n",
    "heatmaps = []\n",
    "INTERESTED_CONV_LAYERS = [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\", \"conv2d_5\", \"conv2d_6\"]\n",
    "layer_list = [(layer.name, layer) for layer in moodel.layers if \"conv\" in layer.name]\n",
    "for layer in layer_list:\n",
    "    if layer[0] in INTERESTED_CONV_LAYERS:\n",
    "        some_conv_layer = moodel.get_layer(layer[0])\n",
    "        grads = K.gradients(pred_vector_output, some_conv_layer.output)[0]\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "        iterate = K.function([moodel.input], [pooled_grads, some_conv_layer.output[0]])\n",
    "        pooled_grads_value, conv_layer_output_value = iterate([sample_img])\n",
    "\n",
    "        for i in range(moodel.get_layer(layer[0]).output_shape[-1]):\n",
    "            conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "        heatmaps.append(np.mean(conv_layer_output_value, axis=-1))\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name,hm) in enumerate(zip(INTERESTED_CONV_LAYERS, heatmaps)):\n",
    "    ax = plt.subplot(1, 6, i+1)\n",
    "    img_heatmap = np.maximum(hm, 0)\n",
    "    img_heatmap /= np.max(img_heatmap)\n",
    "    ax.imshow(img_heatmap, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.title(name)\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
